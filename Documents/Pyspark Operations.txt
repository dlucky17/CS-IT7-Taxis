Setup:

spark = SparkSession.builder.master('spark://172.25.24.242:7077').getOrCreate()
sqlCtx = SQLContext(spark.sparkContext, spark)

(if you are running in the pyspark shell, spark will have been defined already)


Creating a DataFrame:

import schemas

table = 'table_you_want_to_read'
schema = schemas.<theSchemaYouNeed>
df = sqlCtx.read.csv('hdfs://172.25.24.242:54310/user/csit7/%s/part-m-00000' % table, schema)

For example: table = 'cluster_data_sample', schema = schemas.clusterDataSchema
